{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PACKAGES LOADED\n",
      "NETWORK READY\n",
      "FUNCTIONS READY\n",
      "0.748019\n"
     ]
    }
   ],
   "source": [
    "# 原始链接：https://gist.githubusercontent.com/sjchoi86/1757dd2fadba31393ab65c9f43af19ab/raw/9b429a96dd80540637dffb4f9b303c1caa484acb/mlp.py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline  \n",
    "print (\"PACKAGES LOADED\")\n",
    "\n",
    "train=pd.read_csv('Train.csv')\n",
    "test=pd.read_csv('Test.csv')\n",
    "train_data=train[['AMOUNT_MAX', 'PROBABILITY_ThirdQuartile', 'Repeater_Index_Max', 'Back_and_Forth_Counter_Max', 'Forward_Count_Max', 'Quarterly_Positive_Momentum_Max',\n",
    "      'RATIO_REPEATER_TO_TOTAL', 'OVERALL_SLOPE', 'OVERALL_SLOPE_MIDPOINT', 'OPPORTUNITY_HUNG_FOR_LONG']]\n",
    "train_target=train['TGT_LOST']\n",
    "train_target1=pd.get_dummies(train_target).values\n",
    "test_x=test[['AMOUNT_MAX', 'PROBABILITY_ThirdQuartile', 'Repeater_Index_Max', 'Back_and_Forth_Counter_Max', 'Forward_Count_Max', 'Quarterly_Positive_Momentum_Max',\n",
    "      'RATIO_REPEATER_TO_TOTAL', 'OVERALL_SLOPE', 'OVERALL_SLOPE_MIDPOINT', 'OPPORTUNITY_HUNG_FOR_LONG']]\n",
    "test_target=test['TGT_LOST']\n",
    "\n",
    "# NETWORK TOPOLOGIES\n",
    "n_hidden_1 = 256 \n",
    "n_hidden_2 = 128 \n",
    "n_input    = 10 \n",
    "n_classes  = 2  \n",
    "\n",
    "# INPUTS AND OUTPUTS\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "    \n",
    "# NETWORK PARAMETERS\n",
    "stddev = 0.1\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_normal([n_input, n_hidden_1], stddev=stddev)),\n",
    "    'h2': tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2], stddev=stddev)),\n",
    "    'out': tf.Variable(tf.random_normal([n_hidden_2, n_classes], stddev=stddev))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "print (\"NETWORK READY\")\n",
    "\n",
    "def mlp(_X, _weights, _biases):\n",
    "    layer_1 = tf.nn.sigmoid(tf.add(tf.matmul(_X, _weights['h1']), _biases['b1'])) \n",
    "    layer_2 = tf.nn.sigmoid(tf.add(tf.matmul(layer_1, _weights['h2']), _biases['b2']))\n",
    "    return (tf.matmul(layer_2, _weights['out']) + _biases['out'])\n",
    "  \n",
    "# PREDICTION\n",
    "pred = mlp(x, weights, biases)\n",
    "\n",
    "# LOSS AND OPTIMIZER\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y)) \n",
    "# optm = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(cost) \n",
    "optm = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost) \n",
    "result_my=tf.arg_max(pred, 1)\n",
    "corr = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))    \n",
    "accr = tf.reduce_mean(tf.cast(corr, \"float\"))\n",
    "\n",
    "# INITIALIZER\n",
    "init = tf.global_variables_initializer()\n",
    "print (\"FUNCTIONS READY\")\n",
    "\n",
    "# PARAMETERS\n",
    "training_epochs = 20\n",
    "batch_size      = 100\n",
    "display_step    = 4\n",
    "# LAUNCH THE GRAPH\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "# OPTIMIZE\n",
    "# 一共16707行test数据，预测准确的有13599行，准确率82%，训练时间1分钟，训练次数10\n",
    "with tf.Session() as sess:\n",
    "    accuracy=tf.reduce_mean(tf.cast(tf.equal(tf.arg_max(y,1),tf.arg_max(pred,1)),tf.float32))\n",
    "    training_step=tf.train.AdamOptimizer().minimize(cost)\n",
    "    result_my=tf.arg_max(pred,1)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        sess.run(training_step,feed_dict={x:train_data,y:train_target1})\n",
    "        if i%1000==0:\n",
    "            accuracyPringing=sess.run(accuracy,feed_dict={x:train_data,y:train_target1})\n",
    "            print(accuracyPringing)\n",
    "    \n",
    "    pred=sess.run(result_my,feed_dict={x:test_x})\n",
    "    np.savetxt(\"predict.csv\", pred);\n",
    "\n",
    "# SAVE\n",
    "#trainimg   = mnist.train.images\n",
    "#trainlabel = mnist.train.labels\n",
    "#testimg    = mnist.test.images\n",
    "#testlabel  = mnist.test.labels\n",
    "#w1   = sess.run(weights['h1'])\n",
    "#w2   = sess.run(weights['h2'])\n",
    "#wout = sess.run(weights['out'])\n",
    "#b1   = sess.run(biases['b1'])\n",
    "#b2   = sess.run(biases['b2'])\n",
    "#bout = sess.run(biases['out'])\n",
    "\n",
    "# SAVE TO MAT FILE \n",
    "#savepath = './data/mlp.mat'\n",
    "#scipy.io.savemat(savepath\n",
    "#   , mdict={'trainimg': trainimg, 'trainlabel': trainlabel\n",
    "#           , 'testimg': testimg, 'testlabel': testlabel\n",
    "#           , 'w1': w1, 'w2': w2, 'wout': wout, 'b1': b1, 'b2': b2, 'bout': bout})\n",
    "#print (\"%s SAVED.\" % (savepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
